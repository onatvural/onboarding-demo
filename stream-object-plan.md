# Stream Object Mimari DokÃ¼mantasyonu

**Proje:** Demo-YKP - YapÄ± Kredi PortfÃ¶y AI Asistan
**Tarih:** Ocak 2025
**Stack:** Next.js 15, AI SDK v5.0.59, Zod, Edge Runtime

---

## BÃ–LÃœM 1: Mevcut Mimari Analizi

### 1.1 Stream Object Nedir ve Neden KullandÄ±k

**Stream Object,** Vercel AI SDK'nÄ±n yapÄ±landÄ±rÄ±lmÄ±ÅŸ veri (structured data) streaming Ã¶zelliÄŸidir. Geleneksel `streamText`'in aksine, sadece dÃ¼z metin deÄŸil, **JSON objeleri** stream eder.

**Neden gerekli?**

1. **YapÄ±landÄ±rÄ±lmÄ±ÅŸ Veri Ä°htiyacÄ±:** 8 aÅŸamalÄ± form akÄ±ÅŸÄ±mÄ±zda her adÄ±mda:
   - Text mesajÄ±
   - Butonlar (array)
   - previousAnswers (nested object)
   - Step numarasÄ±
   - isComplete durumu
   - Summary (fon Ã¶nerileri ile birlikte)

   DÃ¼z metin ile bu yapÄ±yÄ± yÃ¶netmek imkansÄ±z.

2. **Type Safety:** Zod schema ile TypeScript type inference, compile-time validation.

3. **Progressive Rendering:** Obje kÄ±smi gelirken UI gÃ¼ncellenebilir (Ã¶rn: buttons henÃ¼z gelmeden text render edilebilir).

4. **Validation:** AI Ã§Ä±ktÄ±sÄ± schema'ya uymuyorsa hata verir, gÃ¼venlik ve tutarlÄ±lÄ±k saÄŸlar.

**Alternatifler ve Neden SeÃ§medik:**

| YÃ¶ntem | AvantajlarÄ± | DezavantajlarÄ± | Neden KullanmadÄ±k |
|--------|------------|----------------|-------------------|
| `streamText` | Basit, hÄ±zlÄ± | Sadece text, yapÄ±landÄ±rÄ±lmamÄ±ÅŸ | Form data stream edilemez |
| `generateObject` | Tek seferde tÃ¼m obje | Streaming yok, bekleme sÃ¼resi uzun | UX kÃ¶tÃ¼, 30sn+ bekletir |
| JSON in Text | Basit implementation | Manuel parsing, type safety yok, AI halÃ¼sinasyon riski | GÃ¼vensiz, karmaÅŸÄ±k |
| SSE Events | Browser native | Server tarafÄ±nda fazla kod, chunk management zor | NDJSON daha basit |

**NDJSON vs SSE:**
- **NDJSON:** Her satÄ±r bir JSON â†’ daha az overhead, AI SDK native support
- **SSE:** `data: {...}` format â†’ daha verbose, ekstra parsing

SeÃ§imimiz: **`streamObject` + NDJSON**

---

### 1.2 Mimari Genel BakÄ±ÅŸ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER BROWSER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  React Component (chat.tsx)                              â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ User Input â†’ handleStreamingRequest()              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Fetch POST /api/chat                            â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ AbortController for cancellation                â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                          â†“                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ NDJSON Stream Parser                               â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ ReadableStream.getReader()                      â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ TextDecoder (UTF-8)                             â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Line-by-line JSON.parse()                       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Buffer management for incomplete lines          â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                          â†“                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ State Update (setMessages)                         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Partial<ConversationObject>                     â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Progressive UI update                           â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Defensive rendering (optional chaining)         â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                          â†“                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ UI Rendering                                       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Text message (markdown)                         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Buttons (motion animated)                       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Fund cards (if summary exists)                  â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†• HTTPS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      NEXT.JS SERVER (Edge Runtime)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  API Route: /app/api/chat/route.ts                      â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  POST /api/chat                                          â”‚  â”‚
â”‚  â”‚    â†“                                                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ Request Processing                                 â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Parse messages from req.json()                  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Context management: .slice(-10)                 â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Dynamic prompt: inject fund DB if step 7-8     â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚    â†“                                                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ streamObject() - AI SDK                            â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ model: 'openai/gpt-4.1-mini' (via AI Gateway)  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ schema: conversationSchema (Zod)               â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ messages: recentMessages                        â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ system: dynamic prompt string                   â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚    â†“                                                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ partialObjectStream                                â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Async iterator over partial objects             â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Each iteration = more complete object           â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚    â†“                                                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ NDJSON Stream Builder                              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ ReadableStream                                  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ for await (partialObject)                       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ JSON.stringify + '\n'                           â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ TextEncoder.encode()                            â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ controller.enqueue()                            â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚    â†“                                                      â”‚  â”‚
â”‚  â”‚  Response (Content-Type: application/x-ndjson)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†• HTTPS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI GATEWAY / OPENAI API                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ GPT-4.1 Mini Model                                           â”‚
â”‚  â€¢ Structured Output with JSON Schema                           â”‚
â”‚  â€¢ Streaming Response (Server-Sent Events internally)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Veri AkÄ±ÅŸÄ± Ã–zeti:**
1. User input â†’ React component
2. Fetch POST â†’ `/api/chat` with message history
3. Server: Context management, dynamic prompt injection
4. AI SDK `streamObject` â†’ calls OpenAI API
5. AI generates structured JSON progressively
6. `partialObjectStream` async iterator â†’ partial objects
7. Server wraps in NDJSON format
8. Client parses line-by-line
9. State updates trigger React re-renders
10. UI shows progressive updates (text â†’ buttons â†’ cards)

---

### 1.3 Teknoloji Stack'i

| Teknoloji | Versiyon | KullanÄ±m AmacÄ± | Kritik Ã–zellikler |
|-----------|----------|----------------|-------------------|
| **Next.js** | 15.0.0 | Full-stack framework | App Router, Edge Runtime, Streaming |
| **AI SDK** | 5.0.59 | AI integration | `streamObject`, `partialObjectStream` |
| **Zod** | 4.1.11 | Schema validation | Type inference, runtime validation |
| **React** | 19.0.0 | UI library | Streaming support, Suspense |
| **TypeScript** | 5.x | Type safety | Zod type inference |
| **Motion/React** | 12.23.22 | Animations | Button fade-in effects |
| **TailwindCSS** | 3.4.1 | Styling | Utility-first CSS |

**AI SDK v5.0.59 Ã–zellikleri:**
- âœ… `streamObject` ile structured output
- âœ… `partialObjectStream` async iterator
- âŒ `useObject` React hook (bu versiyonda yok!)
- âœ… Edge Runtime uyumlu
- âœ… Multiple providers (OpenAI, Anthropic, Google, xAI)

**Neden Edge Runtime?**
1. **DÃ¼ÅŸÃ¼k Latency:** KullanÄ±cÄ±ya en yakÄ±n edge node'dan yanÄ±t
2. **Streaming Optimized:** Native ReadableStream support
3. **SoÄŸuk baÅŸlangÄ±Ã§ yok:** Her zaman hazÄ±r
4. **Cost Efficient:** KullanÄ±m bazlÄ± Ã¼cretlendirme

**Trade-offs:**
- âš ï¸ Node.js API'leri kullanÄ±lamaz (fs, path, etc.)
- âš ï¸ Maksimum execution time: 25 saniye (Vercel Hobby)
- âœ… Bizim use case iÃ§in yeterli (AI yanÄ±t 5-10sn)

---

### 1.4 Kritik BileÅŸenler DetayÄ±

#### **A. Backend: streamObject Implementation**

**Dosya:** `app/api/chat/route.ts`

**Kod Anatomisi:**

```typescript
import { streamObject } from 'ai';
import { conversationSchema } from '@/lib/schemas';

export const runtime = 'edge'; // Edge Runtime aktif

export async function POST(req: Request) {
  const { messages } = await req.json();

  // CRITICAL: Context window management
  const recentMessages = messages.slice(-10); // Son 10 mesaj

  // OPTIMIZATION: Dynamic prompt injection
  const conversationLength = messages.length;
  const isNearFinalStep = conversationLength >= 14;

  const result = streamObject({
    model: 'openai/gpt-4.1-mini',     // AI Gateway format
    schema: conversationSchema,        // Zod schema
    messages: recentMessages,          // Chat history
    system: `...${isNearFinalStep ? mockFunds : ''}...`, // Dynamic
  });

  // NDJSON Stream Builder
  const encoder = new TextEncoder();
  const stream = new ReadableStream({
    async start(controller) {
      try {
        for await (const partialObject of result.partialObjectStream) {
          const line = JSON.stringify(partialObject) + '\n';
          controller.enqueue(encoder.encode(line));
        }
        controller.close();
      } catch (error) {
        controller.error(error);
      }
    },
  });

  return new Response(stream, {
    headers: {
      'Content-Type': 'application/x-ndjson',
      'Cache-Control': 'no-cache',
    },
  });
}
```

**Kritik Noktalar:**

1. **`messages.slice(-10)`** â†’ Token tasarrufu
   - GPT-4.1 Mini context limit: ~16K tokens
   - System prompt: ~700 token
   - 10 mesaj: ~2000 token
   - Toplam: ~2700 token (gÃ¼venli alan)

2. **`isNearFinalStep`** â†’ Dynamic prompt
   - Step 1-6: Fon DB yok â†’ ~400 token
   - Step 7-8: Fon DB eklenir â†’ ~1500 token
   - AkÄ±llÄ± token yÃ¶netimi

3. **`for await of partialObjectStream`** â†’ Progressive streaming
   - Her iteration: Daha eksiksiz obje
   - Ã–rnek akÄ±ÅŸ:
     ```
     Iteration 1: { step: 1, text: "Merha..." }
     Iteration 2: { step: 1, text: "Merhaba! Ben..." }
     Iteration 3: { step: 1, text: "Merhaba! Ben YapÄ±...", buttons: [] }
     Iteration 4: { step: 1, text: "...", buttons: ["Evet", "..."] }
     ```

4. **NDJSON Format:**
   ```
   {"step":1,"text":"Merhaba"}\n
   {"step":1,"text":"Merhaba! Ben"}\n
   {"step":1,"text":"Merhaba! Ben YapÄ± Kredi..."}\n
   ```
   - Her satÄ±r valid JSON
   - `\n` delimiter
   - Incomplete line buffer'da bekletilir

#### **B. Frontend: NDJSON Parser**

**Dosya:** `components/chat.tsx`

**Kod Anatomisi:**

```typescript
const handleStreamingRequest = async (userMessage: string) => {
  const controller = new AbortController(); // Cancellation support

  const response = await fetch('/api/chat', {
    method: 'POST',
    body: JSON.stringify({ messages: [...] }),
    signal: controller.signal, // AbortController signal
  });

  const reader = response.body.getReader();
  const decoder = new TextDecoder(); // UTF-8 decoder
  let buffer = ''; // Incomplete line buffer

  while (true) {
    const { value, done } = await reader.read();
    if (done) break;

    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split('\n');

    // CRITICAL: Keep last incomplete line
    buffer = lines.pop() || '';

    for (const line of lines) {
      if (line.trim()) {
        try {
          const partialObject = JSON.parse(line);

          // Update last assistant message
          setMessages((prev) => {
            const newMessages = [...prev];
            const lastMessage = newMessages[newMessages.length - 1];

            if (lastMessage?.role === 'assistant') {
              lastMessage.content = partialObject.text || '';
              lastMessage.object = partialObject;
            }

            return newMessages;
          });
        } catch (e) {
          console.warn('JSON parse error:', line);
        }
      }
    }
  }
};
```

**Kritik Noktalar:**

1. **Buffer Management:**
   ```
   Received: {"step":1,"tex
   Buffer: {"step":1,"tex

   Received: t":"Hello"}
   Buffer: {"step":1,"text":"Hello"}
   Parse: âœ“
   ```

2. **`decoder.decode(value, { stream: true })`:**
   - Multi-byte UTF-8 karakterler iÃ§in gerekli
   - TÃ¼rkÃ§e karakterler: Ã§, ÄŸ, Ä±, Ã¶, ÅŸ, Ã¼
   - `stream: true` â†’ Incomplete bytes buffer'da bekletilir

3. **State Update Pattern:**
   ```typescript
   setMessages((prev) => {
     const newMessages = [...prev]; // IMMUTABLE
     const lastMessage = newMessages[newMessages.length - 1];
     lastMessage.object = partialObject; // MUTATE copy
     return newMessages;
   });
   ```

4. **AbortController:**
   ```typescript
   const stopGeneration = () => {
     if (abortControllerRef.current) {
       abortControllerRef.current.abort();
       setIsLoading(false);
     }
   };
   ```
   - User "Stop" butonuna basÄ±nca stream kesilir
   - `AbortError` catch edilir, UI gÃ¼ncellenir

#### **C. Schema: Zod Validation**

**Dosya:** `lib/schemas.ts`

```typescript
import { z } from 'zod';

export const conversationSchema = z.object({
  step: z.number().min(1).max(8),              // Step validation
  text: z.string(),                            // AI message
  buttons: z.array(z.string()).optional(),     // Button options
  previousAnswers: z.object({                  // User answers
    vade: z.string().optional(),
    urun: z.string().optional(),
    nitelikli: z.boolean().optional(),
    nakit: z.string().optional(),
    karakter: z.string().optional(),
    ilgiAlanlari: z.array(z.string()).optional(),
  }).optional(),
  isComplete: z.boolean().default(false),      // Flow completion
  summary: z.object({                          // Final recommendations
    riskProfili: z.string(),
    onerilecekFonlar: z.array(z.object({
      id: z.string(),
      ad: z.string(),
      risk: z.string(),
      getiri: z.number(),
      minimumTutar: z.number(),
      kategori: z.string(),
      aciklama: z.string(),
      detayUrl: z.string(),
    })),
  }).optional(),
});

export type ConversationObject = z.infer<typeof conversationSchema>;
```

**Zod'un RolÃ¼:**

1. **Runtime Validation:**
   - AI Ã§Ä±ktÄ±sÄ± schema'ya uymazsa hata
   - Ã–rnek: `step: 9` â†’ âŒ Validation error

2. **Type Inference:**
   ```typescript
   type ConversationObject = {
     step: number;
     text: string;
     buttons?: string[];
     // ...
   }
   ```

3. **Optional vs Required:**
   - `text`: Required (her adÄ±mda olmalÄ±)
   - `buttons`: Optional (step 8'de yok)
   - `summary`: Optional (sadece step 8'de)

4. **Nested Objects:**
   - `previousAnswers` â†’ State management
   - `onerilecekFonlar` â†’ Complex array of objects

---

### 1.5 Optimizasyon Stratejileri

#### **1.5.1 Context Window Management**

**Sorun:** Her request'te tÃ¼m conversation history gÃ¶nderilirse token limit aÅŸÄ±lÄ±r.

**Ã‡Ã¶zÃ¼m:**
```typescript
const recentMessages = messages.slice(-10);
```

**Analiz:**
- 8 step Ã— 2 mesaj (user + AI) = 16 mesaj
- Son 10 mesaj = ~5 exchange
- Step 3'ten itibaren eski mesajlar kesilir
- Trade-off: AI eski detaylarÄ± "unutur" ama critical info `previousAnswers`'da

**Alternatif YaklaÅŸÄ±mlar:**
| YÃ¶ntem | Avantaj | Dezavantaj |
|--------|---------|------------|
| Son N mesaj | Basit, sabit token | Context loss |
| Token counting | Dinamik, optimal | KarmaÅŸÄ±k, tokenizer gerekli |
| Summarization | Tam context | Ekstra AI call, latency |
| Embedding search | Semantic context | KarmaÅŸÄ±k, DB gerekli |

**SeÃ§imimiz:** Son 10 mesaj (basit + yeterli)

#### **1.5.2 Dynamic Prompt Injection**

**Sorun:** Fon veritabanÄ± (11 fon Ã— ~100 token = 1100 token) her request'te gereksiz.

**Ã‡Ã¶zÃ¼m:**
```typescript
const isNearFinalStep = conversationLength >= 14;

system: `
...
${isNearFinalStep ? `
## FON VERÄ°TABANI
${JSON.stringify(mockFunds, null, 2)}
` : ''}
`
```

**Token Tasarrufu:**
- Step 1-6: ~400 token
- Step 7-8: ~1500 token
- Ortalama 6 step Ã— 400 + 2 step Ã— 1500 = 5400 token
- Static: 8 step Ã— 1500 = 12000 token
- **Tasarruf: %55** ğŸ‰

#### **1.5.3 System Prompt Minimizasyonu**

**Ã–ncesi:** ~2500 token (verbose YAML, examples, repetitive)

**SonrasÄ±:** ~400-700 token

**Optimizasyon Teknikleri:**
1. **KÄ±sa cÃ¼mleler:** "Her aÅŸamada kullanÄ±cÄ±ya soru sor..." â†’ "Her step'te soru sor"
2. **Listeler:** DetaylÄ± aÃ§Ä±klamalar â†’ Bullet points
3. **Ã–rnekleri kaldÄ±rma:** AI zaten anlÄ±yor
4. **Tekrar eden yapÄ±larÄ± silme:** `previousAnswers: "[Ã¶nceki]"` her step'te â†’ 1 kez aÃ§Ä±kla

**SonuÃ§:** Token %75 azalma, AI performansÄ± aynÄ±

#### **1.5.4 Defensive Rendering**

**Sorun:** Partial object'te field'lar henÃ¼z gelmemiÅŸ olabilir.

**Ã‡Ã¶zÃ¼m: Optional Chaining**

```typescript
// âŒ BAD: Runtime error if buttons undefined
{message.object.buttons.map((btn) => <Button>{btn}</Button>)}

// âœ… GOOD: Safe rendering
{message.object?.buttons && message.object.buttons.length > 0 && (
  <div>
    {message.object.buttons.map((btn) => <Button>{btn}</Button>)}
  </div>
)}
```

**Partial Object Progression:**
```typescript
// Iteration 1
{ step: 1, text: "Merh" }
// message.object?.buttons â†’ undefined (safe)

// Iteration 2
{ step: 1, text: "Merhaba!", buttons: [] }
// message.object?.buttons â†’ [] (empty, don't render)

// Iteration 3
{ step: 1, text: "Merhaba!", buttons: ["Evet", "HayÄ±r"] }
// message.object?.buttons â†’ ["Evet", "HayÄ±r"] (render!)
```

**Pattern:**
```typescript
{fon.ad && <CardTitle>{fon.ad}</CardTitle>}
{fon.getiri && <span>%{fon.getiri}</span>}
{fon.minimumTutar && <span>{fon.minimumTutar.toLocaleString('tr-TR')}</span>}
```

---

### 1.6 KarÅŸÄ±laÅŸÄ±lan Sorunlar ve Ã‡Ã¶zÃ¼mler

#### **Sorun 1: AI SDK v5.0.59'da `useObject` Hook Yok**

**Hata:**
```
Module not found: Can't resolve 'ai/react'
```

**Neden:**
- AI SDK v3-v4'te `useObject` hook vardÄ±
- v5.0.59'da kaldÄ±rÄ±ldÄ±, sadece `streamObject` var
- Docs'ta hala eski Ã¶rnekler var

**Ã‡Ã¶zÃ¼m:**
Manuel NDJSON parser implementasyonu:
```typescript
const reader = response.body.getReader();
const decoder = new TextDecoder();
let buffer = '';

while (true) {
  const { value, done } = await reader.read();
  if (done) break;

  buffer += decoder.decode(value, { stream: true });
  const lines = buffer.split('\n');
  buffer = lines.pop() || '';

  for (const line of lines) {
    const partialObject = JSON.parse(line);
    setMessages(/* update */);
  }
}
```

**Lesson Learned:** AI SDK versiyonlarÄ±nda breaking changes olabiliyor, docs gÃ¼ncel olmayabiliyor.

#### **Sorun 2: Grok Context Overflow (3. Sorudan Sonra Duruyor)**

**Hata:**
- Grok model 3. sorudan sonra yanÄ±t vermeyi kesiyor
- Error yok, sadece duruyor

**Neden:**
1. System prompt Ã§ok uzun: ~2500 token
2. Fon veritabanÄ± her request'te: +1100 token
3. Conversation history: +1500 token (6 mesaj)
4. **Toplam: ~5100 token**
5. Grok-4-fast context limit: ~4000 token (tahmini)

**Ã‡Ã¶zÃ¼m:**
```typescript
// 1. System prompt minimize: 2500 â†’ 400 token
// 2. Dynamic injection: Fon DB sadece step 7-8
// 3. Context management: Son 10 mesaj

const recentMessages = messages.slice(-10);
const isNearFinalStep = conversationLength >= 14;
```

**SonuÃ§:** 8 sorunun tamamÄ± Ã§alÄ±ÅŸÄ±yor

#### **Sorun 3: TypeScript RefObject Type Error**

**Hata:**
```typescript
const canvasRef: RefObject<HTMLCanvasElement> = useRef<HTMLCanvasElement>(null);
// Error: Type 'RefObject<HTMLCanvasElement | null>' is not assignable to type 'RefObject<HTMLCanvasElement>'
```

**Neden:**
- `useRef<HTMLCanvasElement>(null)` â†’ `RefObject<HTMLCanvasElement | null>`
- Explicit type annotation conflicts

**Ã‡Ã¶zÃ¼m:**
```typescript
// âŒ BAD
const canvasRef: RefObject<HTMLCanvasElement> = useRef<HTMLCanvasElement>(null);

// âœ… GOOD: Let TypeScript infer
const canvasRef = useRef<HTMLCanvasElement>(null);
```

**Lesson Learned:** TypeScript inference > explicit typing

#### **Sorun 4: Gradient Text `background` vs `backgroundClip` Conflict**

**Hata:**
```
Updating a style property during rerender (background) when a conflicting property is set (backgroundClip)
```

**Neden:**
```typescript
style={{
  background: 'linear-gradient(...)', // Shorthand
  backgroundClip: 'text',             // Longhand
}}
```
React shorthand ve longhand karÄ±ÅŸÄ±mÄ±nÄ± sevmiyor.

**Ã‡Ã¶zÃ¼m:**
```typescript
style={{
  backgroundImage: 'linear-gradient(...)', // Longhand
  backgroundClip: 'text',
}}
```

---

### 1.7 KullanÄ±m SenaryolarÄ±

**Stream Object Ä°deal KullanÄ±m AlanlarÄ±:**

1. **Multi-Step Forms:**
   - Onboarding flows
   - KYC (Know Your Customer) processes
   - Medical questionnaires
   - Survey applications

2. **AI Agents:**
   - Tool calling with structured output
   - Multi-step reasoning
   - Planning and execution

3. **Structured Content Generation:**
   - Blog post outlines (title, sections, tags)
   - Product descriptions (name, features, price)
   - Email templates (subject, body, CTA)

4. **Data Extraction:**
   - Resume parsing (name, experience, skills)
   - Invoice extraction (items, amounts, total)
   - Document classification

5. **Progressive UI Updates:**
   - Loading states with partial data
   - Skeleton screens â†’ real content
   - Incremental table filling

**Not Uygun Olmayan Senaryolar:**

1. **Basit Chatbots:** DÃ¼z metin yeterli â†’ `streamText` kullan
2. **Static JSON:** Streaming gerekmez â†’ `generateObject` kullan
3. **Large Binary Data:** JSON inefficient â†’ custom binary protocol

---

### 1.8 Performans Ä°puÃ§larÄ±

#### **1. Token Optimization**

```typescript
// âŒ BAD: Verbose prompt
system: `
You are a helpful assistant. Your task is to ask the user questions
about their investment preferences. You should be polite and professional.
Always remember to validate the user's input and provide helpful feedback.
...
`

// âœ… GOOD: Concise prompt
system: `Investment profile assistant. Ask 8 questions, validate input, be professional.`
```

**Kural:** Her kelime token = para. KÄ±sa ve net ol.

#### **2. Schema Simplification**

```typescript
// âŒ BAD: Over-engineered
z.object({
  metadata: z.object({
    timestamp: z.string(),
    version: z.string(),
    environment: z.enum(['dev', 'prod']),
  }),
  // ...
})

// âœ… GOOD: Essential fields only
z.object({
  step: z.number(),
  text: z.string(),
  // ...
})
```

**Kural:** Schema cÃ ng karmaÅŸÄ±k = AI validation zorlaÅŸÄ±r = hata riski artar.

#### **3. Streaming Frequency**

```typescript
// Partial object update sÄ±klÄ±ÄŸÄ± AI kontrolÃ¼nde
// Ã‡ok sÄ±k â†’ Network overhead
// Ã‡ok seyrek â†’ UX kÃ¶tÃ¼

// Optimal: AI SDK default (~100-200ms aralÄ±klar)
```

#### **4. Message History Trimming**

```typescript
// Context window = para
// Optimize et:

const recentMessages = messages
  .filter(m => m.role === 'user' || m.content) // Empty messages filtrele
  .slice(-10); // Son N mesaj
```

#### **5. Error Handling**

```typescript
try {
  const partialObject = JSON.parse(line);
  setMessages(/* ... */);
} catch (e) {
  console.warn('JSON parse error:', line); // Log but don't crash
  // Partial line, next iteration'da dÃ¼zelir
}
```

**Kural:** Stream errors geÃ§ici olabilir, UI crash ettirme.

---

### 1.9 Metrics ve Monitoring

**Track Edilmesi Gerekenler:**

1. **Token Usage:**
   - Input tokens per request
   - Output tokens per request
   - Cost per conversation

2. **Latency:**
   - Time to first byte (TTFB)
   - Time to first token
   - Total streaming duration

3. **Error Rates:**
   - JSON parse errors
   - Schema validation errors
   - Network timeouts

4. **User Behavior:**
   - Step completion rate
   - Button vs text input ratio
   - Conversation abandonment points

**Ã–rnek Implementation:**

```typescript
// Backend
const startTime = Date.now();

// ... streamObject ...

console.log('Streaming completed:', {
  duration: Date.now() - startTime,
  messageCount: messages.length,
  // Send to analytics
});
```

---

## BÃ–LÃœM 2: Kurulum ReÃ§etesi

Bu bÃ¶lÃ¼m, **baÅŸka bir Next.js projesinde** aynÄ± Stream Object mimarisini sÄ±fÄ±rdan kurmanÄ±z iÃ§in adÄ±m adÄ±m talimatlar iÃ§erir.

Her phase baÄŸÄ±msÄ±zdÄ±r ve Claude Code'a copy-paste edilerek Ã§alÄ±ÅŸtÄ±rÄ±labilir.

---

### PHASE 1: Proje Setup ve Dependencies

**Hedef:** Next.js 15 projesi oluÅŸtur, gerekli paketleri yÃ¼kle.

**Claude Code'a VereceÄŸiniz Prompt:**

```markdown
Yeni bir Next.js 15 projesi oluÅŸtur ve Stream Object iÃ§in gerekli paketleri yÃ¼kle.

## Gereksinimler:
1. Next.js 15 (App Router)
2. TypeScript
3. TailwindCSS
4. AI SDK (Vercel)
5. Zod

## Komutlar:
```bash
# 1. Next.js projesi oluÅŸtur
npx create-next-app@latest my-stream-app --typescript --tailwind --app --no-src-dir

# 2. Proje dizinine gir
cd my-stream-app

# 3. AI SDK ve Zod yÃ¼kle
npm install ai zod

# 4. OpenAI provider yÃ¼kle (veya baÅŸka provider)
npm install @ai-sdk/openai

# 5. Development server baÅŸlat (test iÃ§in)
npm run dev
```

## Dosya YapÄ±sÄ±:
```
my-stream-app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â””â”€â”€ route.ts          # API endpoint
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”œâ”€â”€ page.tsx                  # Ana sayfa
â”‚   â””â”€â”€ globals.css
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ schemas.ts                # Zod schemas
â”œâ”€â”€ components/
â”‚   â””â”€â”€ chat.tsx                  # Chat component
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ tailwind.config.ts
```

## Environment Variables:
`.env.local` dosyasÄ± oluÅŸtur:
```env
# OpenAI API Key (veya AI Gateway URL)
OPENAI_API_KEY=sk-...

# Veya AI Gateway kullanÄ±yorsan:
# AI_GATEWAY_API_KEY=...
```

## DoÄŸrulama:
- `npm run dev` Ã§alÄ±ÅŸÄ±yor mu?
- http://localhost:3000 aÃ§Ä±lÄ±yor mu?
- TypeScript hatalarÄ± yok mu?

Bu adÄ±mlarÄ± tamamla ve "PHASE 1 tamamlandÄ±" de.
```

**Beklenen Ã‡Ä±ktÄ±:**
- Ã‡alÄ±ÅŸan Next.js 15 projesi
- TÃ¼m paketler yÃ¼klÃ¼
- `.env.local` dosyasÄ± oluÅŸturulmuÅŸ

---

### PHASE 2: Backend - Schema ve API Route

**Hedef:** Zod schema tanÄ±mla, API route oluÅŸtur, `streamObject` implementasyonu.

**Claude Code'a VereceÄŸiniz Prompt:**

```markdown
Stream Object backend'ini kur: Zod schema + API route.

## 1. Zod Schema OluÅŸtur

`lib/schemas.ts` dosyasÄ± oluÅŸtur:

```typescript
import { z } from 'zod';

// Conversation object schema
export const conversationSchema = z.object({
  step: z.number().min(1).max(5),           // KaÃ§ aÅŸama varsa
  text: z.string(),                         // AI'Ä±n mesajÄ±
  buttons: z.array(z.string()).optional(),  // Button seÃ§enekleri
  isComplete: z.boolean().default(false),   // AkÄ±ÅŸ tamamlandÄ± mÄ±?

  // (Opsiyonel) User cevaplarÄ±nÄ± saklamak iÃ§in:
  answers: z.object({
    q1: z.string().optional(),
    q2: z.string().optional(),
    // Ä°htiyacÄ±nÄ±za gÃ¶re geniÅŸletin
  }).optional(),

  // (Opsiyonel) Final summary:
  summary: z.object({
    result: z.string(),
    data: z.array(z.any()),
  }).optional(),
});

// TypeScript type inference
export type ConversationObject = z.infer<typeof conversationSchema>;
```

## 2. API Route OluÅŸtur

`app/api/chat/route.ts` dosyasÄ± oluÅŸtur:

```typescript
import { streamObject } from 'ai';
import { openai } from '@ai-sdk/openai'; // veya baÅŸka provider
import { conversationSchema } from '@/lib/schemas';

export const runtime = 'edge'; // Edge Runtime kullan

export async function POST(req: Request) {
  try {
    // 1. Request body'yi parse et
    const { messages } = await req.json();

    // 2. (Opsiyonel) Context management
    const recentMessages = messages.slice(-10);

    // 3. streamObject Ã§aÄŸÄ±r
    const result = streamObject({
      model: openai('gpt-4-turbo'), // Model seÃ§imi
      schema: conversationSchema,    // Zod schema
      messages: recentMessages,      // Chat history
      system: `
        Sen yardÄ±mcÄ± bir asistansÄ±n.
        5 aÅŸamalÄ± bir form akÄ±ÅŸÄ± yÃ¶net:
        1. KullanÄ±cÄ±ya hoÅŸ geldin mesajÄ± ver
        2. Ä°sim sor
        3. Email sor
        4. Tercih sor
        5. Ã–zet gÃ¶ster ve isComplete: true yap

        Her step'te:
        - text: KullanÄ±cÄ±ya mesajÄ±n
        - buttons: (Opsiyonel) HÄ±zlÄ± cevap seÃ§enekleri
        - answers: Ã–nceki cevaplarÄ± sakla
      `,
    });

    // 4. NDJSON stream oluÅŸtur
    const encoder = new TextEncoder();
    const stream = new ReadableStream({
      async start(controller) {
        try {
          for await (const partialObject of result.partialObjectStream) {
            const line = JSON.stringify(partialObject) + '\n';
            controller.enqueue(encoder.encode(line));
          }
          controller.close();
        } catch (error) {
          console.error('Stream error:', error);
          controller.error(error);
        }
      },
    });

    // 5. Response dÃ¶ndÃ¼r
    return new Response(stream, {
      headers: {
        'Content-Type': 'application/x-ndjson',
        'Cache-Control': 'no-cache',
      },
    });

  } catch (error) {
    console.error('API error:', error);
    return new Response(JSON.stringify({ error: 'Internal server error' }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' },
    });
  }
}
```

## 3. Test Et

Terminal'de test request gÃ¶nder:

```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Merhaba"}]}'
```

Beklenen Ã§Ä±ktÄ±: NDJSON stream (her satÄ±r bir JSON objesi)

```
{"step":1,"text":"Merhaba!","isComplete":false}
{"step":1,"text":"Merhaba! HoÅŸ geldiniz","isComplete":false}
{"step":1,"text":"Merhaba! HoÅŸ geldiniz. Ä°sminiz nedir?","buttons":[],"isComplete":false}
```

"PHASE 2 tamamlandÄ±" de.
```

**Beklenen Ã‡Ä±ktÄ±:**
- `lib/schemas.ts` oluÅŸturuldu
- `app/api/chat/route.ts` oluÅŸturuldu
- Curl ile test edildi, NDJSON stream Ã§alÄ±ÅŸÄ±yor

---

### PHASE 3: Frontend - State Management

**Hedef:** React component'inde message state'i kur, TypeScript tipleri tanÄ±mla.

**Claude Code'a VereceÄŸiniz Prompt:**

```markdown
Frontend iÃ§in state management ve TypeScript tiplerini kur.

## 1. Message Type TanÄ±mla

`components/chat.tsx` dosyasÄ± oluÅŸtur:

```typescript
'use client';

import { useState, useRef } from 'react';
import type { ConversationObject } from '@/lib/schemas';

// Message tipi
type Message = {
  id: string;
  role: 'user' | 'assistant';
  content: string;                        // Display text
  object?: Partial<ConversationObject>;   // Partial: HenÃ¼z tam gelmemiÅŸ olabilir
};

export function Chat() {
  // State
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);

  // Refs
  const abortControllerRef = useRef<AbortController | null>(null);

  // Placeholder functions (Phase 4'te implement edeceÄŸiz)
  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    console.log('TODO: Implement streaming');
  };

  const stopGeneration = () => {
    abortControllerRef.current?.abort();
  };

  return (
    <div className="max-w-2xl mx-auto p-4">
      <h1 className="text-2xl font-bold mb-4">Stream Object Chat</h1>

      {/* Messages */}
      <div className="space-y-4 mb-4">
        {messages.map((message) => (
          <div
            key={message.id}
            className={`p-3 rounded-lg ${
              message.role === 'user'
                ? 'bg-blue-100 text-right'
                : 'bg-gray-100'
            }`}
          >
            {/* Text */}
            <div>{message.content}</div>

            {/* Buttons (if exists) */}
            {message.object?.buttons && message.object.buttons.length > 0 && (
              <div className="flex gap-2 mt-2">
                {message.object.buttons.map((btn, idx) => (
                  <button
                    key={idx}
                    className="px-3 py-1 bg-white border rounded hover:bg-gray-50"
                    onClick={() => {/* TODO: Handle button click */}}
                  >
                    {btn}
                  </button>
                ))}
              </div>
            )}

            {/* Summary (if complete) */}
            {message.object?.isComplete && message.object?.summary && (
              <div className="mt-4 p-3 bg-green-50 border border-green-200 rounded">
                <p className="font-semibold">Ã–zet:</p>
                <p>{message.object.summary.result}</p>
              </div>
            )}
          </div>
        ))}
      </div>

      {/* Input Form */}
      <form onSubmit={handleSubmit} className="flex gap-2">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="MesajÄ±nÄ±zÄ± yazÄ±n..."
          className="flex-1 px-4 py-2 border rounded"
          disabled={isLoading}
        />
        <button
          type="submit"
          disabled={isLoading || !input.trim()}
          className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600 disabled:opacity-50"
        >
          {isLoading ? 'Durdur' : 'GÃ¶nder'}
        </button>
      </form>
    </div>
  );
}
```

## 2. Ana Sayfada Kullan

`app/page.tsx` dosyasÄ±nÄ± gÃ¼ncelle:

```typescript
import { Chat } from '@/components/chat';

export default function Home() {
  return <Chat />;
}
```

## 3. Test Et

- http://localhost:3000 aÃ§Ä±ldÄ±ÄŸÄ±nda Chat component gÃ¶rÃ¼nÃ¼yor mu?
- Input field ve gÃ¶nder butonu Ã§alÄ±ÅŸÄ±yor mu?
- Console'da "TODO: Implement streaming" mesajÄ± gÃ¶rÃ¼nÃ¼yor mu?

"PHASE 3 tamamlandÄ±" de.
```

**Beklenen Ã‡Ä±ktÄ±:**
- `components/chat.tsx` oluÅŸturuldu
- UI render ediliyor
- State management hazÄ±r
- HenÃ¼z streaming yok (placeholder)

---

### PHASE 4: Frontend - NDJSON Streaming Parser

**Hedef:** Manuel NDJSON parser implement et, progressive UI update'i aktif et.

**Claude Code'a VereceÄŸiniz Prompt:**

```markdown
NDJSON streaming parser'Ä± implement et ve UI'yÄ± progressive update et.

## 1. handleStreamingRequest Function

`components/chat.tsx` iÃ§inde `handleSubmit` fonksiyonunu gÃ¼ncelle:

```typescript
const handleSubmit = async (e: React.FormEvent) => {
  e.preventDefault();
  if (!input.trim() || isLoading) return;

  // 1. User mesajÄ±nÄ± ekle
  const userMessage: Message = {
    id: Date.now().toString(),
    role: 'user',
    content: input.trim(),
  };
  setMessages((prev) => [...prev, userMessage]);
  setInput('');

  // 2. BoÅŸ assistant mesajÄ± ekle (streaming iÃ§in)
  const assistantMessage: Message = {
    id: (Date.now() + 1).toString(),
    role: 'assistant',
    content: '',
  };
  setMessages((prev) => [...prev, assistantMessage]);

  // 3. Streaming request baÅŸlat
  await handleStreamingRequest(input.trim());
};

const handleStreamingRequest = async (userMessage: string) => {
  setIsLoading(true);

  // AbortController oluÅŸtur (cancellation iÃ§in)
  const controller = new AbortController();
  abortControllerRef.current = controller;

  try {
    // 4. API'ye POST request
    const response = await fetch('/api/chat', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        messages: [...messages, { role: 'user', content: userMessage }].map(m => ({
          role: m.role,
          content: m.content,
        })),
      }),
      signal: controller.signal,
    });

    if (!response.ok) {
      throw new Error(`API error: ${response.status}`);
    }

    if (!response.body) {
      throw new Error('No response body');
    }

    // 5. ReadableStream reader oluÅŸtur
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let buffer = '';

    // 6. Stream'i oku
    while (true) {
      const { value, done } = await reader.read();

      if (done) break;

      // 7. Decode et ve buffer'a ekle
      buffer += decoder.decode(value, { stream: true });

      // 8. SatÄ±rlara bÃ¶l
      const lines = buffer.split('\n');

      // 9. Son satÄ±r incomplete olabilir, buffer'da tut
      buffer = lines.pop() || '';

      // 10. Her satÄ±rÄ± parse et
      for (const line of lines) {
        if (line.trim()) {
          try {
            const partialObject = JSON.parse(line) as Partial<ConversationObject>;

            // 11. Son assistant mesajÄ±nÄ± gÃ¼ncelle
            setMessages((prev) => {
              const newMessages = [...prev];
              const lastMessage = newMessages[newMessages.length - 1];

              if (lastMessage?.role === 'assistant') {
                lastMessage.content = partialObject.text || '';
                lastMessage.object = partialObject;
              }

              return newMessages;
            });
          } catch (e) {
            console.warn('JSON parse error:', line, e);
          }
        }
      }
    }

  } catch (error: any) {
    if (error.name !== 'AbortError') {
      console.error('Streaming error:', error);

      // Hata mesajÄ± gÃ¶ster
      setMessages((prev) => {
        const newMessages = [...prev];
        const lastMessage = newMessages[newMessages.length - 1];
        if (lastMessage?.role === 'assistant') {
          lastMessage.content = 'ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin.';
        }
        return newMessages;
      });
    }
  } finally {
    setIsLoading(false);
    abortControllerRef.current = null;
  }
};
```

## 2. Button Click Handler

```typescript
const handleButtonClick = async (buttonText: string) => {
  if (isLoading) return;

  // User mesajÄ± olarak button text'i ekle
  const userMessage: Message = {
    id: Date.now().toString(),
    role: 'user',
    content: buttonText,
  };
  setMessages((prev) => [...prev, userMessage]);

  // BoÅŸ assistant mesajÄ±
  const assistantMessage: Message = {
    id: (Date.now() + 1).toString(),
    role: 'assistant',
    content: '',
  };
  setMessages((prev) => [...prev, assistantMessage]);

  // Streaming baÅŸlat
  await handleStreamingRequest(buttonText);
};
```

## 3. Stop Generation

```typescript
const stopGeneration = () => {
  if (abortControllerRef.current) {
    abortControllerRef.current.abort();
    setIsLoading(false);
  }
};
```

## 4. Button onClick BaÄŸla

Render kÄ±smÄ±nda button'a `onClick` ekle:

```typescript
<button
  key={idx}
  className="px-3 py-1 bg-white border rounded hover:bg-gray-50"
  onClick={() => handleButtonClick(btn)}
>
  {btn}
</button>
```

## 5. Submit Button'u GÃ¼ncelle

```typescript
<button
  type={isLoading ? 'button' : 'submit'}
  onClick={isLoading ? stopGeneration : undefined}
  disabled={!isLoading && !input.trim()}
  className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600 disabled:opacity-50"
>
  {isLoading ? 'Durdur' : 'GÃ¶nder'}
</button>
```

## 6. Test Et

1. Mesaj gÃ¶nder
2. AI cevabÄ±nÄ±n kelime kelime geldiÄŸini gÃ¶r (progressive update)
3. Butonlar Ã§Ä±ktÄ±ÄŸÄ±nda tÄ±kla
4. "Durdur" butonuna basarak streaming'i iptal et

"PHASE 4 tamamlandÄ±, streaming Ã§alÄ±ÅŸÄ±yor" de.
```

**Beklenen Ã‡Ä±ktÄ±:**
- NDJSON parser Ã§alÄ±ÅŸÄ±yor
- Progressive UI update aktif
- Butonlar tÄ±klanabilir
- Stop generation Ã§alÄ±ÅŸÄ±yor

---

### PHASE 5: Optimizasyon ve Production Ready

**Hedef:** Context management, error handling, performance optimizations.

**Claude Code'a VereceÄŸiniz Prompt:**

```markdown
Production-ready optimizasyonlarÄ± ekle.

## 1. Context Window Management

`app/api/chat/route.ts` iÃ§inde:

```typescript
export async function POST(req: Request) {
  const { messages } = await req.json();

  // Son 10 mesajÄ± tut (token tasarrufu)
  const recentMessages = messages.slice(-10);

  const result = streamObject({
    model: openai('gpt-4-turbo'),
    schema: conversationSchema,
    messages: recentMessages, // â† Burada
    system: `...`,
  });

  // ...
}
```

## 2. Dynamic Prompt Injection

BÃ¼yÃ¼k data'yÄ± sadece gerektiÄŸinde ekle:

```typescript
const conversationLength = messages.length;
const isNearEnd = conversationLength >= 8; // Son 2-3 step

const result = streamObject({
  // ...
  system: `
    Sen yardÄ±mcÄ± bir asistansÄ±n.
    ${isNearEnd ? `
      ## LARGE DATA
      ${JSON.stringify(yourLargeDatabase)}
    ` : ''}
  `,
});
```

## 3. Auto-Scroll

`components/chat.tsx` iÃ§inde:

```typescript
const messagesEndRef = useRef<HTMLDivElement>(null);

// Auto scroll to bottom
useEffect(() => {
  messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
}, [messages]);

// Render:
<div className="space-y-4 mb-4 max-h-[500px] overflow-y-auto">
  {messages.map((message) => (...))}
  <div ref={messagesEndRef} />
</div>
```

## 4. Loading Indicator

```typescript
{isLoading && messages[messages.length - 1]?.role === 'assistant' && (
  <div className="flex items-center gap-2">
    <div className="w-2 h-2 bg-blue-500 rounded-full animate-bounce" />
    <div className="w-2 h-2 bg-blue-500 rounded-full animate-bounce delay-100" />
    <div className="w-2 h-2 bg-blue-500 rounded-full animate-bounce delay-200" />
  </div>
)}
```

## 5. Error Boundary (Opsiyonel)

`app/error.tsx` dosyasÄ± oluÅŸtur:

```typescript
'use client';

export default function Error({
  error,
  reset,
}: {
  error: Error & { digest?: string };
  reset: () => void;
}) {
  return (
    <div className="flex flex-col items-center justify-center min-h-screen">
      <h2 className="text-2xl font-bold mb-4">Bir ÅŸeyler yanlÄ±ÅŸ gitti!</h2>
      <p className="text-gray-600 mb-4">{error.message}</p>
      <button
        onClick={reset}
        className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600"
      >
        Tekrar Dene
      </button>
    </div>
  );
}
```

## 6. Environment Variables Validation

`app/api/chat/route.ts` baÅŸÄ±nda:

```typescript
if (!process.env.OPENAI_API_KEY) {
  throw new Error('OPENAI_API_KEY environment variable is not set');
}
```

## 7. Rate Limiting (Opsiyonel)

Vercel KV veya Redis ile:

```typescript
import { ratelimit } from '@/lib/redis';

export async function POST(req: Request) {
  const ip = req.headers.get('x-forwarded-for') || 'anonymous';
  const { success } = await ratelimit.limit(ip);

  if (!success) {
    return new Response('Too many requests', { status: 429 });
  }

  // ...
}
```

## 8. Vercel Analytics

`app/layout.tsx`:

```typescript
import { Analytics } from '@vercel/analytics/react';

export default function RootLayout({ children }) {
  return (
    <html>
      <body>
        {children}
        <Analytics />
      </body>
    </html>
  );
}
```

## 9. Build Test

```bash
npm run build
npm run start
```

Build hatasÄ±z tamamlanmalÄ±.

## 10. Deploy

```bash
# Vercel CLI yÃ¼kle
npm i -g vercel

# Deploy et
vercel --prod
```

"PHASE 5 tamamlandÄ±, production ready" de.
```

**Beklenen Ã‡Ä±ktÄ±:**
- Optimizasyonlar eklendi
- Error handling robust
- Build baÅŸarÄ±lÄ±
- Production'da Ã§alÄ±ÅŸÄ±yor

---

### BONUS: Debug ve Troubleshooting

**SÄ±k KarÅŸÄ±laÅŸÄ±lan Sorunlar:**

1. **`streamObject` hatasÄ±:**
   ```
   Error: Model not found
   ```
   **Ã‡Ã¶zÃ¼m:** `.env.local`'de API key doÄŸru mu?

2. **JSON parse error:**
   ```
   JSON parse error: Unexpected token
   ```
   **Ã‡Ã¶zÃ¼m:** Buffer management doÄŸru mu? `lines.pop()` var mÄ±?

3. **TypeScript hatasÄ±:**
   ```
   Property 'object' does not exist on type 'Message'
   ```
   **Ã‡Ã¶zÃ¼m:** `Partial<ConversationObject>` kullanÄ±ldÄ± mÄ±?

4. **Stream duruyor:**
   **Ã‡Ã¶zÃ¼m:** Context window aÅŸÄ±ldÄ± mÄ±? Token sayÄ±sÄ±nÄ± azalt.

5. **Buttons render olmuyor:**
   **Ã‡Ã¶zÃ¼m:** `message.object?.buttons && message.object.buttons.length > 0` kontrolÃ¼ var mÄ±?

---

## SonuÃ§

Bu dokÃ¼mantasyonla:

1. âœ… Stream Object mimarisini **anladÄ±nÄ±z**
2. âœ… Mevcut projemizdeki implementasyonu **incediniz**
3. âœ… SÄ±fÄ±rdan **kurulum reÃ§etesi** aldÄ±nÄ±z
4. âœ… Optimizasyon ve **best practices** Ã¶ÄŸrendiniz
5. âœ… Troubleshooting **rehberi** edindiniz

**Next Steps:**

- [ ] Kendi use case'iniz iÃ§in schema tasarlayÄ±n
- [ ] System prompt'u Ã¶zelleÅŸtirin
- [ ] UI/UX iyileÅŸtirmeleri ekleyin
- [ ] Production'a deploy edin
- [ ] Metrics ve monitoring ekleyin

**Sorular veya ek bilgi iÃ§in:**
- AI SDK Docs: https://sdk.vercel.ai/docs
- Zod Docs: https://zod.dev
- Next.js Docs: https://nextjs.org/docs

---

**HazÄ±rlayan:** Claude Code
**Tarih:** Ocak 2025
**Lisans:** MIT
